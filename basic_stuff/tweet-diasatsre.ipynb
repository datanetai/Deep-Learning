{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  nlp-getting-started.zip\n",
      "  inflating: sample_submission.csv   \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "!unzip nlp-getting-started.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['keyword'].unique().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['keyword'].value_counts().head(10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sklean countvectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow=CountVectorizer(max_features=1000)\n",
    "train_bow=bow.fit_transform(train['text'])\n",
    "test_bow=bow.transform(test['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fill nan keyword with 0\n",
    "train['keyword'].fillna('0',inplace=True)\n",
    "test['keyword'].fillna('0',inplace=True)\n",
    "\n",
    "#assign int to keyword\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label=LabelEncoder()\n",
    "train['keyword_label']=label.fit_transform(train['keyword'])\n",
    "test['keyword_label']=label.transform(test['keyword'])\n",
    "#X- train_bow+ train['keyword_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywords_train=train['keyword'].values\n",
    "#concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_train,train['target'],test_size=0.2,random_state=42)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.793827971109652"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression(max_iter=10000)\n",
    "logreg.fit(x_train,y_train)\n",
    "#score\n",
    "logreg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8573070607553366"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prediction on test\n",
    "pred=logreg.predict(test_bow)\n",
    "#save prediction\n",
    "pd.DataFrame({'id':test['id'],'target':pred}).to_csv('submission.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T03:05:08.360757Z",
     "iopub.status.busy": "2022-05-25T03:05:08.360488Z",
     "iopub.status.idle": "2022-05-25T03:06:27.241029Z",
     "shell.execute_reply": "2022-05-25T03:06:27.240036Z",
     "shell.execute_reply.started": "2022-05-25T03:05:08.360723Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_word_ids':   0           ['input_1[0][0]']                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'default': (None,   9591041     ['keras_layer[0][0]',            \n",
      "                                256),                             'keras_layer[0][1]',            \n",
      "                                 'encoder_outputs':               'keras_layer[0][2]']            \n",
      "                                 [(None, 128, 256),                                               \n",
      "                                 (None, 128, 256)],                                               \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 256),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 256)}                                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            257         ['keras_layer_1[0][3]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,591,298\n",
      "Trainable params: 257\n",
      "Non-trainable params: 9,591,041\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#bert\n",
    "import tensorflow_text as text\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessor = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "encoder_inputs = preprocessor(text_input)\n",
    "encoder = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/2\",\n",
    "    trainable=False,)\n",
    "outputs = encoder(encoder_inputs)\n",
    "pooled_output = outputs[\"pooled_output\"]      # [batch_size, 256].\n",
    "sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 256].\n",
    "#dense layer\n",
    "dense=tf.keras.layers.Dense(1,activation='sigmoid')(pooled_output)\n",
    "model=tf.keras.Model(inputs=text_input,outputs=dense)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5)\n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "callbacks=[reduce_lr,early_stopping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 0.6516 - accuracy: 0.6130 - val_loss: 0.6091 - val_accuracy: 0.7052 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 19s 200ms/step - loss: 0.5951 - accuracy: 0.6970 - val_loss: 0.5659 - val_accuracy: 0.7452 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 19s 200ms/step - loss: 0.5670 - accuracy: 0.7274 - val_loss: 0.5408 - val_accuracy: 0.7603 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 19s 200ms/step - loss: 0.5496 - accuracy: 0.7381 - val_loss: 0.5263 - val_accuracy: 0.7498 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 19s 201ms/step - loss: 0.5373 - accuracy: 0.7432 - val_loss: 0.5182 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 19s 200ms/step - loss: 0.5281 - accuracy: 0.7473 - val_loss: 0.5135 - val_accuracy: 0.7735 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 19s 200ms/step - loss: 0.5200 - accuracy: 0.7539 - val_loss: 0.4977 - val_accuracy: 0.7715 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 19s 200ms/step - loss: 0.5143 - accuracy: 0.7606 - val_loss: 0.4930 - val_accuracy: 0.7722 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 19s 200ms/step - loss: 0.5094 - accuracy: 0.7634 - val_loss: 0.4874 - val_accuracy: 0.7774 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 19s 200ms/step - loss: 0.5055 - accuracy: 0.7642 - val_loss: 0.4847 - val_accuracy: 0.7800 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27f10bdc90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train['text'],train['target'],batch_size=64,epochs=10,validation_split=0.2,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/hf/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 5.42MB/s]\n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 16.3kB/s]\n",
      "Downloading: 100%|██████████| 483/483 [00:00<00:00, 278kB/s]\n",
      "Downloading: 100%|██████████| 347M/347M [00:06<00:00, 57.4MB/s] \n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'classifier', 'pre_classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification \n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\",num_labels=2)\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "train_tokens = tokenizer(train.text.values.tolist(), return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "test_tokens = tokenizer(test.text.values.tolist(), return_tensors=\"tf\", padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select attention_mask and input_ids and token_type_ids\n",
    "train_input_ids = train_tokens[\"input_ids\"]\n",
    "train_attention_mask = train_tokens[\"attention_mask\"]\n",
    "test_input_ids = test_tokens[\"input_ids\"]\n",
    "test_attention_mask = test_tokens[\"attention_mask\"]\n",
    "tr_token=tf.concat([train_input_ids,train_attention_mask],axis=1)\n",
    "te_token=tf.concat([test_input_ids,test_attention_mask],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=train.target.values\n",
    "train_data=tf.data.Dataset.from_tensor_slices((tr_token,train_labels)).shuffle(len(train_labels)).batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_layer_norm', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'dropout_39', 'pre_classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "119/119 [==============================] - 126s 979ms/step - loss: 0.6992 - accuracy: 0.5529\n",
      "Epoch 2/5\n",
      "119/119 [==============================] - 121s 1s/step - loss: 0.6857 - accuracy: 0.5703\n",
      "Epoch 3/5\n",
      "119/119 [==============================] - 123s 1s/step - loss: 0.6844 - accuracy: 0.5706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce0033d330>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=2)\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=6e-4)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "model.fit(train_data,batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer,TFAutoModelForSequenceClassification ,AutoConfig\n",
    "\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"vinai/bertweet-base\",num_labels=2)\n",
    "berttweet = TFAutoModelForSequenceClassification.from_config(config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\",num_labels=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = tokenizer(train.text.values.tolist(), return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "test_tokens = tokenizer(test.text.values.tolist(), return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "#select attention_mask and input_ids and token_type_ids\n",
    "train_input_ids = train_tokens[\"input_ids\"]\n",
    "train_attention_mask = train_tokens[\"attention_mask\"]\n",
    "test_input_ids = test_tokens[\"input_ids\"]\n",
    "test_attention_mask = test_tokens[\"attention_mask\"]\n",
    "tr_token=tf.concat([train_input_ids,train_attention_mask],axis=1)\n",
    "te_token=tf.concat([test_input_ids,test_attention_mask],axis=1)\n",
    "train_data=tf.data.Dataset.from_tensor_slices((tr_token,train_labels)).shuffle(len(train_labels)).batch(32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=6e-4)\n",
    "berttweet.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "berttweet.fit(train_data,batch_size=32, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf:Python",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
